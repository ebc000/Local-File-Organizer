Introduction:
Role: You are an expert programming tutor assisting a self-taught coder with basic programming knowledge.

Task: Provide clear, comprehensive coding assistance tailored to my level of understanding.

Context: I have a general grasp of programming concepts but lack deep language-specific knowledge. I need extra help with big-picture understanding and detailed explanations.

Instructions:
1. Provide exact, complete code segments in clearly marked code blocks that can be directly copied and pasted.
2. Clearly indicate where in the existing code these segments should be placed.
3. Break down complex tasks into smaller, manageable steps.
4. Include detailed, step-by-step explanations for each code segment, assuming I may need clarification on fundamental concepts.
5. Anticipate common errors and provide preventive advice, explaining why these errors occur and how to avoid them.
6. Include comments within the code to explain the purpose and functionality of each section.

Before responding:
- Think carefully about the additions or changes you are suggesting to the code.
- Review the overall codebase and ensure there will be no unintended consequences from the changes.
- Consider potential edge cases or limitations in the proposed solution.

Output Format:
1. An overall educational assessment of the issue or question, followed by complete code file(s) sequentially as needed to address the issue.

User Message:

Hello,

hi, im a self taught coder with LLM assistance. here's my codebase for my project.


Combined Core Files Content:

File: data_processing.py

import re
from multiprocessing import Pool, cpu_count
from nexa.gguf import NexaVLMInference, NexaTextInference
from file_utils import sanitize_filename, create_folder
import os
import shutil
import sys
import contextlib

# Global variables to hold the models
image_inference = None
text_inference = None

@contextlib.contextmanager
def suppress_stdout_stderr():
    """A context manager that redirects stdout and stderr to devnull."""
    with open(os.devnull, 'w') as devnull:
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        sys.stdout = devnull
        sys.stderr = devnull
        try:
            yield
        finally:
            sys.stdout = old_stdout
            sys.stderr = old_stderr

def initialize_models():
    """Initialize the models if they haven't been initialized yet."""
    global image_inference, text_inference
    if image_inference is None or text_inference is None:
        with suppress_stdout_stderr():
            # Initialize the models
            model_path = "llava-v1.6-vicuna-7b:q4_0"
            model_path_text = "gemma-2-2b-instruct:q4_0"

            # Initialize the image inference model
            image_inference = NexaVLMInference(
                model_path=model_path,
                local_path=None,
                stop_words=[],
                temperature=0.3,
                max_new_tokens=256,  # Reduced to speed up processing
                top_k=3,
                top_p=0.2,
                profiling=False
            )

            # Initialize the text inference model
            text_inference = NexaTextInference(
                model_path=model_path_text,
                local_path=None,
                stop_words=[],
                temperature=0.5,
                max_new_tokens=256,  # Reduced to speed up processing
                top_k=3,
                top_p=0.3,
                profiling=False
            )

def get_text_from_generator(generator):
    """Extract text from the generator response."""
    response_text = ""
    try:
        while True:
            response = next(generator)
            choices = response.get('choices', [])
            for choice in choices:
                delta = choice.get('delta', {})
                if 'content' in delta:
                    response_text += delta['content']
    except StopIteration:
        pass
    return response_text

def generate_image_metadata(image_path):
    """Generate description, folder name, and filename for an image file."""
    initialize_models()

    # Generate description
    description_prompt = "Please provide a detailed description of this image, focusing on the main subject and any important details."
    description_generator = image_inference._chat(description_prompt, image_path)
    description = get_text_from_generator(description_generator).strip()

    # Generate filename
    filename_prompt = f"""Based on the description below, generate a specific and descriptive filename (2-4 words) for the image.
Do not include any data type words like 'image', 'jpg', 'png', etc. Use only letters and connect words with underscores.

Description: {description}

Example:
Description: A photo of a sunset over the mountains.
Filename: sunset_over_mountains

Now generate the filename.

Filename:"""
    filename_response = text_inference.create_completion(filename_prompt)
    filename = filename_response['choices'][0]['text'].strip()
    filename = filename.replace('Filename:', '').strip()
    sanitized_filename = sanitize_filename(filename)

    if not sanitized_filename:
        sanitized_filename = 'untitled_image'

    # Generate folder name from description
    foldername_prompt = f"""Based on the description below, generate a general category or theme (1-2 words) for this image.
This will be used as the folder name. Do not include specific details or words from the filename.

Description: {description}

Example:
Description: A photo of a sunset over the mountains.
Category: landscapes

Now generate the category.

Category:"""
    foldername_response = text_inference.create_completion(foldername_prompt)
    foldername = foldername_response['choices'][0]['text'].strip()
    foldername = foldername.replace('Category:', '').strip()
    sanitized_foldername = sanitize_filename(foldername)

    if not sanitized_foldername:
        sanitized_foldername = 'images'

    return sanitized_foldername, sanitized_filename, description

def process_single_image(image_path):
    """Process a single image file to generate metadata."""
    foldername, filename, description = generate_image_metadata(image_path)
    print(f"File: {image_path}")
    print(f"Description: {description}")
    print(f"Folder name: {foldername}")
    print(f"Generated filename: {filename}")
    print("-" * 50)
    return {
        'file_path': image_path,
        'foldername': foldername,
        'filename': filename,
        'description': description
    }

def process_image_files(image_paths):
    """Process image files using multiprocessing."""
    with Pool(cpu_count()) as pool:
        data_list = pool.map(process_single_image, image_paths)
    return data_list

def summarize_text_content(text):
    """Summarize the given text content."""
    initialize_models()

    prompt = f"""Provide a concise and accurate summary of the following text, focusing on the main ideas and key details.
Limit your summary to a maximum of 150 words.

Text: {text}

Summary:"""

    response = text_inference.create_completion(prompt)
    summary = response['choices'][0]['text'].strip()
    return summary

def generate_text_metadata(input_text):
    """Generate description, folder name, and filename for a text document."""
    initialize_models()

    # Generate description
    description = summarize_text_content(input_text)

    # Generate filename
    filename_prompt = f"""Based on the summary below, generate a specific and descriptive filename (2-4 words) for the document.
Do not include any data type words like 'text', 'document', 'pdf', etc. Use only letters and connect words with underscores.

Summary: {description}

Example:
Summary: A research paper on the fundamentals of string theory.
Filename: string_theory_fundamentals

Now generate the filename.

Filename:"""
    filename_response = text_inference.create_completion(filename_prompt)
    filename = filename_response['choices'][0]['text'].strip()
    filename = filename.replace('Filename:', '').strip()
    sanitized_filename = sanitize_filename(filename)

    if not sanitized_filename:
        sanitized_filename = 'untitled_document'

    # Generate folder name from summary
    foldername_prompt = f"""Based on the summary below, generate a general category or theme (1-2 words) for this document.
This will be used as the folder name. Do not include specific details or words from the filename.

Summary: {description}

Example:
Summary: A research paper on the fundamentals of string theory.
Category: physics

Now generate the category.

Category:"""
    foldername_response = text_inference.create_completion(foldername_prompt)
    foldername = foldername_response['choices'][0]['text'].strip()
    foldername = foldername.replace('Category:', '').strip()
    sanitized_foldername = sanitize_filename(foldername)

    if not sanitized_foldername:
        sanitized_foldername = 'documents'

    return sanitized_foldername, sanitized_filename, description

def process_single_text_file(args):
    """Process a single text file to generate metadata."""
    file_path, text = args
    foldername, filename, description = generate_text_metadata(text)
    print(f"File: {file_path}")
    print(f"Description: {description}")
    print(f"Folder name: {foldername}")
    print(f"Generated filename: {filename}")
    print("-" * 50)
    return {
        'file_path': file_path,
        'foldername': foldername,
        'filename': filename,
        'description': description
    }

def process_text_files(text_tuples):
    """Process text files using multiprocessing."""
    with Pool(cpu_count()) as pool:
        results = pool.map(process_single_text_file, text_tuples)
    return results

def copy_and_rename_files(data_list, new_path, renamed_files, processed_files):
    """Copy and rename files based on generated metadata."""
    for data in data_list:
        file_path = data['file_path']
        if file_path in processed_files:
            continue
        processed_files.add(file_path)

        # Use folder name which generated from the description
        dir_path = create_folder(new_path, data['foldername'])

        # Use filename which generated from the  description
        new_file_name = data['filename'] + os.path.splitext(file_path)[1]
        new_file_path = os.path.join(dir_path, new_file_name)

        # Handle duplicates
        counter = 1
        while new_file_path in renamed_files or os.path.exists(new_file_path):
            new_file_name = f"{data['filename']}_{counter}" + os.path.splitext(file_path)[1]
            new_file_path = os.path.join(dir_path, new_file_name)
            counter += 1

        shutil.copy2(file_path, new_file_path)
        renamed_files.add(new_file_path)
        print(f"Copied and renamed to: {new_file_path}")
        print("-" * 50)

==================================================

File: file_utils.py

import os
import re
import shutil
from PIL import Image
import pytesseract
import fitz  # PyMuPDF
import docx

def sanitize_filename(name, max_length=50, max_words=5):
    """Sanitize the filename by removing unwanted words and characters."""
    # Remove file extension if present
    name = os.path.splitext(name)[0]
    # Remove unwanted words and data type words
    name = re.sub(
        r'\b(jpg|jpeg|png|gif|bmp|txt|pdf|docx|image|picture|photo|this|that|these|those|here|there|'
        r'please|note|additional|notes|folder|name|sure|heres|a|an|the|and|of|in|'
        r'to|for|on|with|your|answer|should|be|only|summary|summarize|text|category)\b',
        '',
        name,
        flags=re.IGNORECASE
    )
    # Remove non-word characters except underscores
    sanitized = re.sub(r'[^\w\s]', '', name).strip()
    # Replace multiple underscores or spaces with a single underscore
    sanitized = re.sub(r'[\s_]+', '_', sanitized)
    # Convert to lowercase
    sanitized = sanitized.lower()
    # Remove leading/trailing underscores
    sanitized = sanitized.strip('_')
    # Split into words and limit the number of words
    words = sanitized.split('_')
    limited_words = [word for word in words if word]  # Remove empty strings
    limited_words = limited_words[:max_words]
    limited_name = '_'.join(limited_words)
    # Limit length
    return limited_name[:max_length] if limited_name else 'untitled'

def read_docx_file(file_path):
    """Read text content from a .docx file."""
    try:
        doc = docx.Document(file_path)
        full_text = [para.text for para in doc.paragraphs]
        return '\n'.join(full_text)
    except Exception as e:
        print(f"Error reading DOCX file {file_path}: {e}")
        return ""

def read_pdf_file(file_path):
    """Read text content from a PDF file."""
    try:
        doc = fitz.open(file_path)
        # Read only the first few pages to speed up processing
        num_pages_to_read = 3  # Adjust as needed
        full_text = []
        for page_num in range(min(num_pages_to_read, len(doc))):
            page = doc.load_page(page_num)
            full_text.append(page.get_text())
        pdf_content = '\n'.join(full_text)
        return pdf_content
    except Exception as e:
        print(f"Error reading PDF file {file_path}: {e}")
        return ""

def read_image_file(file_path):
    """Extract text from an image file using OCR."""
    try:
        image = Image.open(file_path)
        text = pytesseract.image_to_string(image)
        return text
    except Exception as e:
        print(f"Error reading image file {file_path}: {e}")
        return ""

def read_text_file(file_path):
    """Read text content from a text file."""
    max_chars = 3000  # Limit processing time
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
            text = file.read(max_chars)
        return text
    except Exception as e:
        print(f"Error reading text file {file_path}: {e}")
        return ""

def display_directory_tree(path):
    """Display the directory tree in a format similar to the 'tree' command, including the full path."""
    def tree(dir_path, prefix=''):
        contents = sorted([c for c in os.listdir(dir_path) if not c.startswith('.')])
        pointers = ['├── '] * (len(contents) - 1) + ['└── '] if contents else []
        for pointer, name in zip(pointers, contents):
            full_path = os.path.join(dir_path, name)
            print(prefix + pointer + name)
            if os.path.isdir(full_path):
                extension = '│   ' if pointer == '├── ' else '    '
                tree(full_path, prefix + extension)
    if os.path.isdir(path):
        print(os.path.abspath(path))
        tree(path)
    else:
        print(os.path.abspath(path))

def create_folder(base_path, foldername):
    """Create a directory for the given folder name."""
    sanitized_folder_name = sanitize_filename(foldername)
    dir_path = os.path.join(base_path, sanitized_folder_name)
    os.makedirs(dir_path, exist_ok=True)
    return dir_path

def collect_file_paths(base_path):
    """Collect all file paths from the base directory or single file."""
    if os.path.isfile(base_path):
        return [base_path]
    else:
        file_paths = [
            os.path.join(root, file)
            for root, _, files in os.walk(base_path)
            for file in files
        ]
        return file_paths

def separate_files_by_type(file_paths):
    """Separate files into images and text files based on their extensions."""
    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp')
    text_extensions = ('.txt', '.docx', '.pdf')

    image_files = [fp for fp in file_paths if os.path.splitext(fp.lower())[1] in image_extensions]
    text_files = [fp for fp in file_paths if os.path.splitext(fp.lower())[1] in text_extensions]

    return image_files, text_files  # Return only two values


==================================================

File: main.py

import os
import time

from file_utils import (
    display_directory_tree,
    collect_file_paths,
    separate_files_by_type,
    read_text_file,
    read_pdf_file,
    read_docx_file  # Importing read_docx_file
)

from data_processing import (
    process_image_files,
    process_text_files,
    copy_and_rename_files
)

def main():
    # Paths configuration
    print("-" * 50)
    input_path = input("Enter the path of the directory you want to organize: ").strip()
    if not os.path.exists(input_path):
        print(f"Input path {input_path} does not exist. Please create it and add the necessary files.")
        return

    # Confirm successful input path
    print(f"Input path successfully uploaded: {input_path}")
    print("-" * 50)

    # Default output path is a folder named "organized_folder" in the same directory as the input path
    output_path = input("Enter the path to store organized files and folders (press Enter to use 'organized_folder' in the input directory): ").strip()
    if not output_path:
        # Get the parent directory of the input path and append 'organized_folder'
        output_path = os.path.join(os.path.dirname(input_path), 'organized_folder')

    # Ensure the output directory exists
    os.makedirs(output_path, exist_ok=True)

    # Confirm successful output path
    print(f"Output path successfully upload: {output_path}")
    print("-" * 50)

    # Start processing files
    start_time = time.time()
    file_paths = collect_file_paths(input_path)
    end_time = time.time()

    print(f"Time taken to load file paths: {end_time - start_time:.2f} seconds")
    print("-" * 50)
    print("Directory tree before renaming:")
    display_directory_tree(input_path)

    print("*" * 50)
    print("The file upload was successful. It will take some minutes.")
    print("*" * 50)

    # Separate files by type
    image_files, text_files = separate_files_by_type(file_paths)

    # Process image files
    data_images = process_image_files(image_files)

    # Prepare text tuples for processing
    text_tuples = []
    for fp in text_files:
        ext = os.path.splitext(fp.lower())[1]
        if ext == '.txt':
            text_content = read_text_file(fp)
        elif ext == '.docx':
            text_content = read_docx_file(fp)
        elif ext == '.pdf':
            text_content = read_pdf_file(fp)
        else:
            print(f"Unsupported text file format: {fp}")
            continue  # Skip unsupported file formats
        text_tuples.append((fp, text_content))

    # Process text files
    data_texts = process_text_files(text_tuples)

    # Prepare for copying and renaming
    renamed_files = set()
    processed_files = set()

    # Copy and rename image files
    copy_and_rename_files(data_images, output_path, renamed_files, processed_files)

    # Copy and rename text files
    copy_and_rename_files(data_texts, output_path, renamed_files, processed_files)

    print("-" * 50)
    print(f"the folder content are rename and clean up successfully.")
    print("-" * 50)
    print("Directory tree after copying and renaming:")
    display_directory_tree(output_path)

if __name__ == '__main__':
    main()

==================================================

File: README.md

# Local File Organizer: AI File Management Run Entirely on Your Device, Privacy Assured

Tired of digital clutter? Overwhelmed by disorganized files scattered across your computer? Let AI do the heavy lifting! The Local File Organizer is your personal organizing assistant, using cutting-edge AI to bring order to your file chaos - all while respecting your privacy.

## A Glimpse of How It Works

```
--------------------------------------------------
Enter the path of the directory you want to organize: /home/user/documents/input_files
--------------------------------------------------
Enter the path to store organized files and folders (press Enter to use 'organized_folder' in the input directory)
Output path successfully upload: /home/user/documents/organzied_folder
--------------------------------------------------
Time taken to load file paths: 0.00 seconds
--------------------------------------------------
Directory tree before renaming:
Path/to/your/input/files/or/folder
├── image.jpg
├── document.pdf
├── notes.txt
└── sub_directory
    └── picture.png

1 directory, 4 files
*****************
The files have been uploaded successfully. Processing will take a few minutes.
*****************
File: Path/to/your/input/files/or/folder/image1.jpg
Description: [Generated description]
Folder name: [Generated folder name]
Generated filename: [Generated filename]
--------------------------------------------------
File: Path/to/your/input/files/or/folder/document.pdf
Description: [Generated description]
Folder name: [Generated folder name]
Generated filename: [Generated filename]
--------------------------------------------------
... [Additional files processed]
Directory tree after copying and renaming:
Path/to/your/output/files/or/folder
├── category1
│   └── generated_filename.jpg
├── category2
│   └── generated_filename.pdf
└── category3
    └── generated_filename.png

3 directories, 3 files
```

## What It Does

This intelligent file organizer harnesses the power of advanced AI models, including language models (LMs) and vision-language models (VLMs), to automate the process of organizing files by:


* Scanning a specified input directory for files.
* Content Understanding: 
  - **Textual Analysis**: Uses the [Gemma-2-2B](https://nexaai.com/google/gemma-2-2b-instruct/gguf-q4_0/file) language model (LM) to analyze and summarize text-based content, generating relevant descriptions and filenames.
  - **Visual Content Analysis**: Uses the [LLaVA-v1.6](https://nexaai.com/liuhaotian/llava-v1.6-vicuna-7b/gguf-q4_0/file) vision-language model (VLM), based on Vicuna-7B, to interpret visual files such as images, providing context-aware categorization and descriptions.

* Understanding the content of your files (text, images, and more) to generate relevant descriptions, folder names, and filenames.
* Organizing the files into a new directory structure based on the generated metadata.

The best part? All AI processing happens 100% on your local device using the [Nexa SDK](https://github.com/NexaAI/nexa-sdk). No internet connection required, no data leaves your computer, and no AI API is needed - keeping your files completely private and secure.

We hope this tool can help bring some order to your digital life, making file management a little easier and more efficient.

## Features

- **Automated File Organization:** Automatically sorts files into folders based on AI-generated categories.
- **Intelligent Metadata Generation:** Creates descriptions and filenames using advanced AI models.
- **Support for Multiple File Types:** Handles images, text files, and PDFs.
- **Parallel Processing:** Utilizes multiprocessing to speed up file processing.
- **Customizable Prompts:** Prompts used for AI model interactions can be customized.

## Supported file types

- **Images:** `.png`, `.jpg`, `.jpeg`, `.gif`, `.bmp`
- **Text Files:** `.txt`, `.docx`
- **PDFs:** `.pdf`

## Prerequisites

- **Operating System:** Compatible with Windows, macOS, and Linux.
- **Python Version:** Python 3.12
- **Conda:** Anaconda or Miniconda installed.
- **Git:** For cloning the repository (or you can download the code as a ZIP file).

## Installation

### 1. Clone the Repository

Clone this repository to your local machine using Git:

```zsh
git clone https://github.com/QiuYannnn/Local-File-Organizer.git
```

Or download the repository as a ZIP file and extract it to your desired location.

### 2. Set Up the Python Environment

Create a new Conda environment named `local_file_organizer` with Python 3.12:

```zsh
conda create --name local_file_organizer python=3.12
```

Activate the environment:

```zsh
conda activate local_file_organizer
```

### 3. Install Nexa SDK 🛠️

#### CPU Installation
To install the CPU version of Nexa SDK, run:
```bash
pip install nexaai --prefer-binary --index-url https://nexaai.github.io/nexa-sdk/whl/cpu --extra-index-url https://pypi.org/simple --no-cache-dir
```

#### GPU Installation (Metal - macOS)
For the GPU version supporting Metal (macOS), run:
```bash
CMAKE_ARGS="-DGGML_METAL=ON -DSD_METAL=ON" pip install nexaai --prefer-binary --index-url https://nexaai.github.io/nexa-sdk/whl/metal --extra-index-url https://pypi.org/simple --no-cache-dir
```
For detailed installation instructions of Nexa SDK for **CUDA** and **AMD GPU** support, please refer to the [Installation section](https://github.com/NexaAI/nexa-sdk?tab=readme-ov-file#installation) in the main README.


### 4. Install Dependencies

Ensure you are in the project directory and install the required dependencies using `requirements.txt`:

```zsh
pip install -r requirements.txt
```

**Note:** If you encounter issues with any packages, install them individually:

```zsh
pip install nexa Pillow pytesseract PyMuPDF python-docx
```

With the environment activated and dependencies installed, run the script using:
## Running the Script
```zsh
python main.py
```

The script will:

1. Display the directory tree of your input directory.
2. Inform you that the files have been uploaded and processing will begin.
3. Process each file, generating metadata.
4. Copy and rename the files into the output directory based on the generated metadata.
5. Display the directory tree of your output directory after processing.

**Note:** The actual descriptions, folder names, and filenames will be generated by the AI models based on your files' content.

#### Enter the Input Path
You will be prompted to enter the path of the directory where the files you want to organize are stored. Enter the full path to that directory and press Enter.

```zsh
Enter the path of the directory you want to organize: /path/to/your/input_folder
```

#### Enter the Output Path
Next, you will be prompted to enter the path where you want the organized files to be stored. You can either specify a directory or press Enter to use the default directory (organzied_folder) inside the input directory.

```zsh
Enter the path to store organized files and folders (press Enter to use 'organzied_folder' in the input directory): /path/to/your/output_folder
```
If you press Enter without specifying a path, the script will create a folder named organzied_folder in the input directory to store the organized files.

## Notes

- **SDK Models:**
  - The script uses `NexaVLMInference` and `NexaTextInference` models.
  - Ensure you have access to these models and they are correctly set up.
  - You may need to download model files or configure paths.

- **Dependencies:**
  - **pytesseract:** Requires Tesseract OCR installed on your system.
    - **macOS:** `brew install tesseract`
    - **Ubuntu/Linux:** `sudo apt-get install tesseract-ocr`
    - **Windows:** Download from [Tesseract OCR Windows Installer](https://github.com/UB-Mannheim/tesseract/wiki)
  - **PyMuPDF (fitz):** Used for reading PDFs.

- **Processing Time:**
  - Processing may take time depending on the number and size of files.
  - The script uses multiprocessing to improve performance.

- **Customizing Prompts:**
  - You can adjust prompts in `data_processing.py` to change how metadata is generated.

## License

This project is dual-licensed under the MIT License and Apache 2.0 License. You may choose which license you prefer to use for this project.

- See the [MIT License](LICENSE-MIT) for more details.
- See the [Apache 2.0 License](LICENSE-Apache-2.0) for more details.


==================================================





    
Question:

so i've been getting used to using this program on bigger and bigger directories. i do like it. but i get anxious about loss of the results and CPU time. if i set it on a task and leave it for 30 min, be nice to know i still get the "work" if it fails 25 min into it. granularly improved and saved, so to speak. does that make sense? could you speak to that perhaps human anxiety? if i set a task to describe 100 pictures over a few hours, if failed on 72 would be nice to get the data anyway on the first 71 in a txt or json or something.
 